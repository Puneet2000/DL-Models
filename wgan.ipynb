{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(100,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\\\n",
    "            nn.Linear(512,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024,28*28),\n",
    "            nn.Tanh()\n",
    "            \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x= self.linear(x)\n",
    "        x = x.view(-1, 1,28,28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()      \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(-1,28*28)\n",
    "        validity = self.linear(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "G.cuda()\n",
    "D.cuda()\n",
    "\n",
    "G_opt = torch.optim.RMSprop(G.parameters(), lr=0.00005)\n",
    "D_opt = torch.optim.RMSprop(D.parameters(), lr=0.00005)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "realimages = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "train_loader= torch.utils.data.DataLoader(realimages, batch_size=100,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100... Discriminator Loss: -0.0132... Generator Loss: -4.8579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100... Discriminator Loss: -0.0103... Generator Loss: -2.9883\n",
      "Epoch 3/100... Discriminator Loss: -0.0070... Generator Loss: -1.8536\n",
      "Epoch 4/100... Discriminator Loss: -0.0122... Generator Loss: -0.7711\n",
      "Epoch 5/100... Discriminator Loss: -0.0101... Generator Loss: -0.5260\n",
      "Epoch 6/100... Discriminator Loss: -0.0140... Generator Loss: -0.3988\n",
      "Epoch 7/100... Discriminator Loss: -0.0167... Generator Loss: -0.3485\n",
      "Epoch 8/100... Discriminator Loss: -0.0190... Generator Loss: -0.1979\n",
      "Epoch 9/100... Discriminator Loss: -0.0272... Generator Loss: -0.2762\n",
      "Epoch 10/100... Discriminator Loss: -0.0191... Generator Loss: -0.2125\n",
      "Epoch 11/100... Discriminator Loss: -0.0191... Generator Loss: -0.2609\n",
      "Epoch 12/100... Discriminator Loss: -0.0182... Generator Loss: -0.2196\n",
      "Epoch 13/100... Discriminator Loss: -0.0203... Generator Loss: -0.1684\n",
      "Epoch 14/100... Discriminator Loss: -0.0155... Generator Loss: -0.1857\n",
      "Epoch 15/100... Discriminator Loss: -0.0192... Generator Loss: -0.1846\n",
      "Epoch 16/100... Discriminator Loss: -0.0193... Generator Loss: -0.1797\n",
      "Epoch 17/100... Discriminator Loss: -0.0114... Generator Loss: -0.2276\n",
      "Epoch 18/100... Discriminator Loss: -0.0171... Generator Loss: -0.2158\n",
      "Epoch 19/100... Discriminator Loss: -0.0115... Generator Loss: -0.1534\n",
      "Epoch 20/100... Discriminator Loss: -0.0147... Generator Loss: -0.2143\n",
      "Epoch 21/100... Discriminator Loss: -0.0183... Generator Loss: -0.2350\n",
      "Epoch 22/100... Discriminator Loss: -0.0119... Generator Loss: -0.1487\n",
      "Epoch 23/100... Discriminator Loss: -0.0090... Generator Loss: -0.1669\n",
      "Epoch 24/100... Discriminator Loss: -0.0075... Generator Loss: -0.1577\n",
      "Epoch 25/100... Discriminator Loss: -0.0124... Generator Loss: -0.1800\n",
      "Epoch 26/100... Discriminator Loss: -0.0115... Generator Loss: -0.2341\n",
      "Epoch 27/100... Discriminator Loss: -0.0098... Generator Loss: -0.1953\n",
      "Epoch 28/100... Discriminator Loss: -0.0106... Generator Loss: -0.0981\n",
      "Epoch 29/100... Discriminator Loss: -0.0113... Generator Loss: -0.1300\n",
      "Epoch 30/100... Discriminator Loss: -0.0076... Generator Loss: -0.1342\n",
      "Epoch 31/100... Discriminator Loss: -0.0080... Generator Loss: -0.2501\n",
      "Epoch 32/100... Discriminator Loss: -0.0019... Generator Loss: -0.1681\n",
      "Epoch 33/100... Discriminator Loss: -0.0068... Generator Loss: -0.2186\n",
      "Epoch 34/100... Discriminator Loss: -0.0071... Generator Loss: -0.1710\n",
      "Epoch 35/100... Discriminator Loss: -0.0081... Generator Loss: -0.1657\n",
      "Epoch 36/100... Discriminator Loss: -0.0076... Generator Loss: -0.1579\n",
      "Epoch 37/100... Discriminator Loss: -0.0037... Generator Loss: -0.1478\n",
      "Epoch 38/100... Discriminator Loss: -0.0070... Generator Loss: -0.0923\n",
      "Epoch 39/100... Discriminator Loss: -0.0049... Generator Loss: -0.1444\n",
      "Epoch 40/100... Discriminator Loss: -0.0081... Generator Loss: -0.1704\n",
      "Epoch 41/100... Discriminator Loss: -0.0012... Generator Loss: -0.1914\n",
      "Epoch 42/100... Discriminator Loss: -0.0049... Generator Loss: -0.2066\n",
      "Epoch 43/100... Discriminator Loss: -0.0024... Generator Loss: -0.1719\n",
      "Epoch 44/100... Discriminator Loss: -0.0055... Generator Loss: -0.1423\n",
      "Epoch 45/100... Discriminator Loss: -0.0061... Generator Loss: -0.1463\n",
      "Epoch 46/100... Discriminator Loss: -0.0054... Generator Loss: -0.1946\n",
      "Epoch 47/100... Discriminator Loss: -0.0054... Generator Loss: -0.1405\n",
      "Epoch 48/100... Discriminator Loss: -0.0083... Generator Loss: -0.2179\n",
      "Epoch 49/100... Discriminator Loss: -0.0012... Generator Loss: -0.1631\n",
      "Epoch 50/100... Discriminator Loss: -0.0078... Generator Loss: -0.1911\n",
      "Epoch 51/100... Discriminator Loss: -0.0026... Generator Loss: -0.0840\n",
      "Epoch 52/100... Discriminator Loss: -0.0012... Generator Loss: -0.1869\n",
      "Epoch 53/100... Discriminator Loss: -0.0034... Generator Loss: -0.1888\n",
      "Epoch 54/100... Discriminator Loss: -0.0068... Generator Loss: -0.1795\n",
      "Epoch 55/100... Discriminator Loss: -0.0050... Generator Loss: -0.1582\n",
      "Epoch 56/100... Discriminator Loss: -0.0029... Generator Loss: -0.1526\n",
      "Epoch 57/100... Discriminator Loss: -0.0034... Generator Loss: -0.0869\n",
      "Epoch 58/100... Discriminator Loss: -0.0033... Generator Loss: -0.1513\n",
      "Epoch 59/100... Discriminator Loss: -0.0024... Generator Loss: -0.1657\n",
      "Epoch 60/100... Discriminator Loss: -0.0010... Generator Loss: -0.1497\n",
      "Epoch 61/100... Discriminator Loss: -0.0030... Generator Loss: -0.1184\n",
      "Epoch 62/100... Discriminator Loss: 0.0014... Generator Loss: -0.1373\n",
      "Epoch 63/100... Discriminator Loss: -0.0021... Generator Loss: -0.1414\n",
      "Epoch 64/100... Discriminator Loss: -0.0001... Generator Loss: -0.1355\n",
      "Epoch 65/100... Discriminator Loss: -0.0055... Generator Loss: -0.1522\n",
      "Epoch 66/100... Discriminator Loss: -0.0027... Generator Loss: -0.1198\n",
      "Epoch 67/100... Discriminator Loss: -0.0020... Generator Loss: -0.0814\n",
      "Epoch 68/100... Discriminator Loss: -0.0035... Generator Loss: -0.1283\n",
      "Epoch 69/100... Discriminator Loss: -0.0037... Generator Loss: -0.0888\n",
      "Epoch 70/100... Discriminator Loss: -0.0015... Generator Loss: -0.0939\n",
      "Epoch 71/100... Discriminator Loss: -0.0045... Generator Loss: -0.0898\n",
      "Epoch 72/100... Discriminator Loss: -0.0006... Generator Loss: -0.1052\n",
      "Epoch 73/100... Discriminator Loss: -0.0015... Generator Loss: -0.1183\n",
      "Epoch 74/100... Discriminator Loss: 0.0052... Generator Loss: -0.0721\n",
      "Epoch 75/100... Discriminator Loss: -0.0004... Generator Loss: -0.0740\n",
      "Epoch 76/100... Discriminator Loss: 0.0001... Generator Loss: -0.0891\n",
      "Epoch 77/100... Discriminator Loss: -0.0034... Generator Loss: -0.0485\n",
      "Epoch 78/100... Discriminator Loss: -0.0012... Generator Loss: -0.0645\n",
      "Epoch 79/100... Discriminator Loss: -0.0029... Generator Loss: -0.0972\n",
      "Epoch 80/100... Discriminator Loss: -0.0020... Generator Loss: -0.0930\n",
      "Epoch 81/100... Discriminator Loss: -0.0019... Generator Loss: -0.1117\n",
      "Epoch 82/100... Discriminator Loss: -0.0019... Generator Loss: -0.0798\n",
      "Epoch 83/100... Discriminator Loss: -0.0000... Generator Loss: -0.1300\n",
      "Epoch 84/100... Discriminator Loss: -0.0001... Generator Loss: -0.0414\n",
      "Epoch 85/100... Discriminator Loss: -0.0008... Generator Loss: -0.0498\n",
      "Epoch 86/100... Discriminator Loss: -0.0001... Generator Loss: -0.0743\n",
      "Epoch 87/100... Discriminator Loss: -0.0010... Generator Loss: -0.0450\n",
      "Epoch 88/100... Discriminator Loss: -0.0011... Generator Loss: -0.1111\n",
      "Epoch 89/100... Discriminator Loss: 0.0008... Generator Loss: -0.0816\n",
      "Epoch 90/100... Discriminator Loss: -0.0022... Generator Loss: -0.0131\n",
      "Epoch 91/100... Discriminator Loss: -0.0028... Generator Loss: -0.0745\n",
      "Epoch 92/100... Discriminator Loss: -0.0043... Generator Loss: -0.0654\n",
      "Epoch 93/100... Discriminator Loss: -0.0019... Generator Loss: -0.0404\n",
      "Epoch 94/100... Discriminator Loss: -0.0049... Generator Loss: -0.0630\n",
      "Epoch 95/100... Discriminator Loss: -0.0006... Generator Loss: -0.0624\n",
      "Epoch 96/100... Discriminator Loss: -0.0031... Generator Loss: 0.0229\n",
      "Epoch 97/100... Discriminator Loss: -0.0018... Generator Loss: -0.0385\n",
      "Epoch 98/100... Discriminator Loss: 0.0011... Generator Loss: -0.0372\n",
      "Epoch 99/100... Discriminator Loss: -0.0033... Generator Loss: -0.0431\n",
      "Epoch 100/100... Discriminator Loss: -0.0011... Generator Loss: -0.0406\n",
      "Epoch 101/100... Discriminator Loss: -0.0026... Generator Loss: -0.0156\n",
      "Epoch 102/100... Discriminator Loss: -0.0039... Generator Loss: -0.0155\n",
      "Epoch 103/100... Discriminator Loss: -0.0022... Generator Loss: -0.0247\n",
      "Epoch 104/100... Discriminator Loss: 0.0005... Generator Loss: -0.0004\n",
      "Epoch 105/100... Discriminator Loss: -0.0032... Generator Loss: -0.0418\n",
      "Epoch 106/100... Discriminator Loss: 0.0040... Generator Loss: 0.0208\n",
      "Epoch 107/100... Discriminator Loss: -0.0009... Generator Loss: -0.0733\n",
      "Epoch 108/100... Discriminator Loss: -0.0015... Generator Loss: 0.0245\n",
      "Epoch 109/100... Discriminator Loss: 0.0071... Generator Loss: -0.0192\n",
      "Epoch 110/100... Discriminator Loss: 0.0003... Generator Loss: -0.0642\n",
      "Epoch 111/100... Discriminator Loss: -0.0025... Generator Loss: -0.0340\n",
      "Epoch 112/100... Discriminator Loss: -0.0003... Generator Loss: -0.0221\n",
      "Epoch 113/100... Discriminator Loss: -0.0002... Generator Loss: -0.0129\n",
      "Epoch 114/100... Discriminator Loss: -0.0016... Generator Loss: -0.0854\n",
      "Epoch 115/100... Discriminator Loss: -0.0074... Generator Loss: -0.0141\n",
      "Epoch 116/100... Discriminator Loss: -0.0017... Generator Loss: -0.0410\n",
      "Epoch 117/100... Discriminator Loss: 0.0010... Generator Loss: -0.0367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/100... Discriminator Loss: -0.0006... Generator Loss: -0.0575\n",
      "Epoch 119/100... Discriminator Loss: -0.0024... Generator Loss: -0.0088\n",
      "Epoch 120/100... Discriminator Loss: -0.0013... Generator Loss: -0.0500\n",
      "Epoch 121/100... Discriminator Loss: 0.0010... Generator Loss: 0.0249\n",
      "Epoch 122/100... Discriminator Loss: -0.0007... Generator Loss: -0.0181\n",
      "Epoch 123/100... Discriminator Loss: -0.0007... Generator Loss: -0.0087\n",
      "Epoch 124/100... Discriminator Loss: -0.0008... Generator Loss: -0.0084\n",
      "Epoch 125/100... Discriminator Loss: -0.0012... Generator Loss: -0.0018\n",
      "Epoch 126/100... Discriminator Loss: -0.0008... Generator Loss: 0.0090\n",
      "Epoch 127/100... Discriminator Loss: 0.0032... Generator Loss: -0.0148\n",
      "Epoch 128/100... Discriminator Loss: -0.0035... Generator Loss: -0.1170\n",
      "Epoch 129/100... Discriminator Loss: -0.0025... Generator Loss: -0.0229\n",
      "Epoch 130/100... Discriminator Loss: 0.0024... Generator Loss: -0.0864\n",
      "Epoch 131/100... Discriminator Loss: -0.0008... Generator Loss: -0.0507\n",
      "Epoch 132/100... Discriminator Loss: -0.0028... Generator Loss: -0.0195\n",
      "Epoch 133/100... Discriminator Loss: -0.0027... Generator Loss: -0.0717\n",
      "Epoch 134/100... Discriminator Loss: -0.0038... Generator Loss: 0.0024\n",
      "Epoch 135/100... Discriminator Loss: -0.0054... Generator Loss: 0.0079\n",
      "Epoch 136/100... Discriminator Loss: -0.0026... Generator Loss: 0.0176\n",
      "Epoch 137/100... Discriminator Loss: -0.0022... Generator Loss: -0.0746\n",
      "Epoch 138/100... Discriminator Loss: 0.0031... Generator Loss: -0.0049\n",
      "Epoch 139/100... Discriminator Loss: -0.0014... Generator Loss: -0.0268\n",
      "Epoch 140/100... Discriminator Loss: -0.0026... Generator Loss: -0.0291\n",
      "Epoch 141/100... Discriminator Loss: -0.0021... Generator Loss: 0.0710\n",
      "Epoch 142/100... Discriminator Loss: -0.0015... Generator Loss: -0.0270\n",
      "Epoch 143/100... Discriminator Loss: 0.0028... Generator Loss: -0.1168\n",
      "Epoch 144/100... Discriminator Loss: -0.0007... Generator Loss: -0.0350\n",
      "Epoch 145/100... Discriminator Loss: -0.0021... Generator Loss: -0.0356\n",
      "Epoch 146/100... Discriminator Loss: -0.0006... Generator Loss: -0.1016\n",
      "Epoch 147/100... Discriminator Loss: -0.0005... Generator Loss: -0.0165\n",
      "Epoch 148/100... Discriminator Loss: 0.0020... Generator Loss: 0.0217\n",
      "Epoch 149/100... Discriminator Loss: 0.0031... Generator Loss: 0.0456\n",
      "Epoch 150/100... Discriminator Loss: 0.0007... Generator Loss: -0.0108\n",
      "Epoch 151/100... Discriminator Loss: 0.0022... Generator Loss: -0.0285\n",
      "Epoch 152/100... Discriminator Loss: -0.0010... Generator Loss: -0.0132\n",
      "Epoch 153/100... Discriminator Loss: 0.0007... Generator Loss: -0.0359\n",
      "Epoch 154/100... Discriminator Loss: 0.0015... Generator Loss: -0.0157\n",
      "Epoch 155/100... Discriminator Loss: -0.0001... Generator Loss: -0.0781\n",
      "Epoch 156/100... Discriminator Loss: 0.0023... Generator Loss: 0.0071\n",
      "Epoch 157/100... Discriminator Loss: 0.0008... Generator Loss: 0.0071\n",
      "Epoch 158/100... Discriminator Loss: -0.0001... Generator Loss: -0.0179\n",
      "Epoch 159/100... Discriminator Loss: 0.0018... Generator Loss: -0.0277\n",
      "Epoch 160/100... Discriminator Loss: 0.0019... Generator Loss: -0.0083\n",
      "Epoch 161/100... Discriminator Loss: 0.0013... Generator Loss: -0.0449\n",
      "Epoch 162/100... Discriminator Loss: -0.0010... Generator Loss: 0.0145\n",
      "Epoch 163/100... Discriminator Loss: 0.0003... Generator Loss: 0.0063\n",
      "Epoch 164/100... Discriminator Loss: -0.0007... Generator Loss: 0.0079\n",
      "Epoch 165/100... Discriminator Loss: -0.0001... Generator Loss: -0.0057\n",
      "Epoch 166/100... Discriminator Loss: 0.0004... Generator Loss: 0.0258\n",
      "Epoch 167/100... Discriminator Loss: 0.0013... Generator Loss: -0.0023\n",
      "Epoch 168/100... Discriminator Loss: 0.0004... Generator Loss: 0.0010\n",
      "Epoch 169/100... Discriminator Loss: 0.0003... Generator Loss: -0.0029\n",
      "Epoch 170/100... Discriminator Loss: -0.0001... Generator Loss: -0.0042\n",
      "Epoch 171/100... Discriminator Loss: 0.0001... Generator Loss: -0.0051\n",
      "Epoch 172/100... Discriminator Loss: -0.0001... Generator Loss: 0.0102\n",
      "Epoch 173/100... Discriminator Loss: 0.0002... Generator Loss: -0.0003\n",
      "Epoch 174/100... Discriminator Loss: -0.0011... Generator Loss: -0.0083\n",
      "Epoch 175/100... Discriminator Loss: 0.0001... Generator Loss: -0.0141\n",
      "Epoch 176/100... Discriminator Loss: 0.0005... Generator Loss: 0.0182\n",
      "Epoch 177/100... Discriminator Loss: -0.0002... Generator Loss: -0.0200\n",
      "Epoch 178/100... Discriminator Loss: 0.0004... Generator Loss: 0.0131\n",
      "Epoch 179/100... Discriminator Loss: 0.0009... Generator Loss: 0.0082\n",
      "Epoch 180/100... Discriminator Loss: -0.0004... Generator Loss: -0.0168\n",
      "Epoch 181/100... Discriminator Loss: 0.0002... Generator Loss: -0.0004\n",
      "Epoch 182/100... Discriminator Loss: -0.0007... Generator Loss: 0.0044\n",
      "Epoch 183/100... Discriminator Loss: 0.0001... Generator Loss: -0.0216\n",
      "Epoch 184/100... Discriminator Loss: 0.0003... Generator Loss: -0.0158\n",
      "Epoch 185/100... Discriminator Loss: 0.0002... Generator Loss: 0.0024\n",
      "Epoch 186/100... Discriminator Loss: 0.0001... Generator Loss: 0.0197\n",
      "Epoch 187/100... Discriminator Loss: 0.0021... Generator Loss: -0.0186\n",
      "Epoch 188/100... Discriminator Loss: 0.0001... Generator Loss: 0.0160\n",
      "Epoch 189/100... Discriminator Loss: -0.0007... Generator Loss: -0.0030\n",
      "Epoch 190/100... Discriminator Loss: -0.0001... Generator Loss: -0.0191\n",
      "Epoch 191/100... Discriminator Loss: -0.0003... Generator Loss: 0.0176\n",
      "Epoch 192/100... Discriminator Loss: 0.0007... Generator Loss: 0.0049\n",
      "Epoch 193/100... Discriminator Loss: 0.0004... Generator Loss: -0.0001\n",
      "Epoch 194/100... Discriminator Loss: -0.0008... Generator Loss: 0.0345\n",
      "Epoch 195/100... Discriminator Loss: -0.0016... Generator Loss: 0.0206\n",
      "Epoch 196/100... Discriminator Loss: 0.0007... Generator Loss: 0.0115\n",
      "Epoch 197/100... Discriminator Loss: 0.0004... Generator Loss: 0.0019\n",
      "Epoch 198/100... Discriminator Loss: 0.0006... Generator Loss: -0.0049\n",
      "Epoch 199/100... Discriminator Loss: 0.0014... Generator Loss: -0.0026\n",
      "Epoch 200/100... Discriminator Loss: 0.0003... Generator Loss: -0.0190\n"
     ]
    }
   ],
   "source": [
    "fixed_z = torch.Tensor(100, 100).uniform_(-1, 1)\n",
    "fixed_z = Variable(fixed_z.cuda())\n",
    "for e in range(200):\n",
    "\n",
    "    for n, (x_,_) in enumerate(train_loader):\n",
    "        \n",
    "        x_ = Variable(x_.cuda())\n",
    "        #print(x_[0].shape)\n",
    "\n",
    "        # run real input on Discriminator\n",
    "        D_result_real = D(x_)\n",
    "\n",
    "        # run Generator input on Discriminator\n",
    "        z1_ = torch.Tensor(100 ,100).uniform_(-1, 1)\n",
    "        z1_ = Variable(z1_.cuda())\n",
    "        x_fake = G(z1_)\n",
    "        D_result_fake = D(x_fake)\n",
    "        \n",
    "        D_loss = -(torch.mean(D_result_real) - torch.mean(D_result_fake))\n",
    "\n",
    "        # optimize Discriminator\n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step() \n",
    "        \n",
    "        #Genrator\n",
    "        \n",
    "        z2_ = torch.Tensor(100, 100).uniform_(-1, 1)\n",
    "        z2_ = Variable(z2_.cuda())\n",
    "        G_result = G(z2_)       \n",
    "        output_fake = D(G_result)\n",
    "        G_loss = -torch.mean(output_fake)\n",
    "\n",
    "        G.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_opt.step()\n",
    "        for p in D.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    " \n",
    "    print(\"Epoch {}/{}...\".format(e+1, 100),\"Discriminator Loss: {:.4f}...\".format(D_loss.data[0]),\"Generator Loss: {:.4f}\".format(G_loss.data[0])) \n",
    "    test_images = G(fixed_z)\n",
    "    #print(test_images[0].shape)\n",
    "    save_image(test_images.data,'./samples/WGAN/output.png'.format(e),nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
