{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset \n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim as optim\n",
    "import math\n",
    "import itertools\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "realimages = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(realimages, batch_size=100,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrontEnd(nn.Module):\n",
    "    \"\"\"Front End for D and Q\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FrontEnd,self).__init__()\n",
    "        self.frontend = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1),\n",
    "          nn.LeakyReLU(0.1, inplace=True),\n",
    "          nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "          nn.BatchNorm2d(128),\n",
    "          nn.LeakyReLU(0.1, inplace=True),\n",
    ") \n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = self.frontend(x)\n",
    "        #print(x.shape)\n",
    "        output = output.view(-1,128*7*7)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.probability = nn.Sequential(\n",
    "            nn.Linear(128*7*7, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.probability(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(74, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 *7*7),\n",
    "            nn.BatchNorm1d(128 *7*7),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.generate = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, 7, 7)\n",
    "        x = self.generate(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Q,self).__init__()\n",
    "        self.classprob = nn.Sequential(\n",
    "            nn.Linear(128*7*7, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.classprob(x)\n",
    "        return x\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(batch_size):\n",
    "    idx = np.random.randint(10,size=batch_size)\n",
    "    c = np.zeros((batch_size,10))\n",
    "    c[range(batch_size),idx] = 1\n",
    "    c = torch.Tensor(c)\n",
    "    noise = torch.FloatTensor(batch_size,64)\n",
    "    noise.data.uniform_(-10,10)\n",
    "    z = torch.cat([noise,c],1).view(-1,74)\n",
    "    return z,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "FE = FrontEnd()\n",
    "D = Discriminator()\n",
    "G = Generator()\n",
    "QE = Q()\n",
    "FE,D,G,QE = FE.cuda(),D.cuda(),G.cuda(),QE.cuda()\n",
    "for i in [FE,D,G,QE]:\n",
    "    i.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionD = nn.BCELoss()\n",
    "criterionQ = nn.CrossEntropyLoss()\n",
    "optimizerD = optim.Adam([{'params':FE.parameters()}, {'params':D.parameters()}], lr=0.0002, betas=(0.5, 0.99))\n",
    "optimizerG = optim.Adam([{'params':G.parameters()}, {'params':QE.parameters()}], lr=0.001, betas=(0.5, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "num_test_samples =100\n",
    "idix = np.arange(10).repeat(10)\n",
    "one_hot = np.zeros((num_test_samples, 10))\n",
    "one_hot[range(num_test_samples), idix] = 1\n",
    "fix_noise = torch.FloatTensor(num_test_samples, 64)\n",
    "fix_noise.data.uniform_(-10, 10)\n",
    "fixed_z = torch.cat([fix_noise,torch.Tensor(one_hot)],1).view(-1,74)\n",
    "#print(fixed_z.shape)\n",
    "fixed_z = fixed_z.cuda()\n",
    "\n",
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/infero/.local/lib/python3.6/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch/Iter:0/99, Dloss: 0.9887743592262268, Gloss: 3.324737548828125\n",
      "Epoch/Iter:0/199, Dloss: 0.747309148311615, Gloss: 3.584533452987671\n",
      "Epoch/Iter:0/299, Dloss: 0.5177753567695618, Gloss: 3.793801784515381\n",
      "Epoch/Iter:0/399, Dloss: 0.4259243607521057, Gloss: 3.3666489124298096\n",
      "Epoch/Iter:0/499, Dloss: 0.3369847238063812, Gloss: 2.796945810317993\n",
      "Epoch/Iter:0/599, Dloss: 0.2611375153064728, Gloss: 2.7085366249084473\n",
      "Epoch/Iter:1/99, Dloss: 0.18423286080360413, Gloss: 2.6812591552734375\n",
      "Epoch/Iter:1/199, Dloss: 0.15251821279525757, Gloss: 3.141993999481201\n",
      "Epoch/Iter:1/299, Dloss: 0.12600767612457275, Gloss: 3.281402826309204\n",
      "Epoch/Iter:1/399, Dloss: 0.08165092021226883, Gloss: 3.599621534347534\n",
      "Epoch/Iter:1/499, Dloss: 0.07537064701318741, Gloss: 3.6825878620147705\n",
      "Epoch/Iter:1/599, Dloss: 0.053766991943120956, Gloss: 3.902778148651123\n",
      "Epoch/Iter:2/99, Dloss: 0.050118181854486465, Gloss: 4.235359191894531\n",
      "Epoch/Iter:2/199, Dloss: 0.06988492608070374, Gloss: 4.467583179473877\n",
      "Epoch/Iter:2/299, Dloss: 0.04395372420549393, Gloss: 4.672349452972412\n",
      "Epoch/Iter:2/399, Dloss: 0.12216454744338989, Gloss: 3.9031383991241455\n",
      "Epoch/Iter:2/499, Dloss: 0.055071160197257996, Gloss: 4.331033229827881\n",
      "Epoch/Iter:2/599, Dloss: 0.12428943067789078, Gloss: 3.984022617340088\n",
      "Epoch/Iter:3/99, Dloss: 0.1260632574558258, Gloss: 4.25438117980957\n",
      "Epoch/Iter:3/199, Dloss: 0.06544062495231628, Gloss: 4.300416469573975\n",
      "Epoch/Iter:3/299, Dloss: 0.04835024103522301, Gloss: 4.534678936004639\n",
      "Epoch/Iter:3/399, Dloss: 0.06332021951675415, Gloss: 4.270186901092529\n",
      "Epoch/Iter:3/499, Dloss: 0.04934883117675781, Gloss: 4.414287567138672\n",
      "Epoch/Iter:3/599, Dloss: 0.019554410129785538, Gloss: 5.152884483337402\n",
      "Epoch/Iter:4/99, Dloss: 0.08459239453077316, Gloss: 4.967554092407227\n",
      "Epoch/Iter:4/199, Dloss: 0.3438696563243866, Gloss: 3.5157084465026855\n",
      "Epoch/Iter:4/299, Dloss: 0.06155690178275108, Gloss: 4.4905900955200195\n",
      "Epoch/Iter:4/399, Dloss: 0.17653805017471313, Gloss: 3.9939680099487305\n",
      "Epoch/Iter:4/499, Dloss: 0.46502813696861267, Gloss: 4.730361461639404\n",
      "Epoch/Iter:4/599, Dloss: 0.06697805225849152, Gloss: 4.214254379272461\n",
      "Epoch/Iter:5/99, Dloss: 0.03896253556013107, Gloss: 4.858371734619141\n",
      "Epoch/Iter:5/199, Dloss: 0.04798430949449539, Gloss: 4.556297779083252\n",
      "Epoch/Iter:5/299, Dloss: 0.054280493408441544, Gloss: 4.637497901916504\n",
      "Epoch/Iter:5/399, Dloss: 0.10086501389741898, Gloss: 4.026379108428955\n",
      "Epoch/Iter:5/499, Dloss: 0.22349286079406738, Gloss: 4.861084461212158\n",
      "Epoch/Iter:5/599, Dloss: 0.2994120419025421, Gloss: 4.193546772003174\n",
      "Epoch/Iter:6/99, Dloss: 0.06872868537902832, Gloss: 4.429980278015137\n",
      "Epoch/Iter:6/199, Dloss: 0.45282429456710815, Gloss: 5.909059524536133\n",
      "Epoch/Iter:6/299, Dloss: 0.13493560254573822, Gloss: 5.49443244934082\n",
      "Epoch/Iter:6/399, Dloss: 0.04742271080613136, Gloss: 5.161057949066162\n",
      "Epoch/Iter:6/499, Dloss: 0.07738236337900162, Gloss: 4.197373390197754\n",
      "Epoch/Iter:6/599, Dloss: 0.09954896569252014, Gloss: 4.42450475692749\n",
      "Epoch/Iter:7/99, Dloss: 0.0241810604929924, Gloss: 5.327587127685547\n",
      "Epoch/Iter:7/199, Dloss: 0.13874998688697815, Gloss: 4.338696002960205\n",
      "Epoch/Iter:7/299, Dloss: 0.08848774433135986, Gloss: 4.40800666809082\n",
      "Epoch/Iter:7/399, Dloss: 0.0743662416934967, Gloss: 5.1841230392456055\n",
      "Epoch/Iter:7/499, Dloss: 0.04468277096748352, Gloss: 5.268489360809326\n",
      "Epoch/Iter:7/599, Dloss: 0.16100725531578064, Gloss: 4.074379920959473\n",
      "Epoch/Iter:8/99, Dloss: 0.0786747932434082, Gloss: 4.940882205963135\n",
      "Epoch/Iter:8/199, Dloss: 0.3787887692451477, Gloss: 6.38070821762085\n",
      "Epoch/Iter:8/299, Dloss: 0.1096581444144249, Gloss: 4.198183536529541\n",
      "Epoch/Iter:8/399, Dloss: 0.1595250517129898, Gloss: 4.019390106201172\n",
      "Epoch/Iter:8/499, Dloss: 0.02776479162275791, Gloss: 4.960357189178467\n",
      "Epoch/Iter:8/599, Dloss: 0.02368870936334133, Gloss: 4.941562175750732\n",
      "Epoch/Iter:9/99, Dloss: 0.010999040678143501, Gloss: 5.395923137664795\n",
      "Epoch/Iter:9/199, Dloss: 0.008439937606453896, Gloss: 5.5009894371032715\n",
      "Epoch/Iter:9/299, Dloss: 0.008740179240703583, Gloss: 6.017139911651611\n",
      "Epoch/Iter:9/399, Dloss: 0.005799817852675915, Gloss: 6.1100850105285645\n",
      "Epoch/Iter:9/499, Dloss: 0.003395965788513422, Gloss: 6.812884330749512\n",
      "Epoch/Iter:9/599, Dloss: 0.068890281021595, Gloss: 5.767576217651367\n",
      "Epoch/Iter:10/99, Dloss: 0.11980439722537994, Gloss: 5.157739639282227\n",
      "Epoch/Iter:10/199, Dloss: 0.06630297005176544, Gloss: 5.182681083679199\n",
      "Epoch/Iter:10/299, Dloss: 0.084979347884655, Gloss: 4.737854480743408\n",
      "Epoch/Iter:10/399, Dloss: 0.1572212278842926, Gloss: 4.535127639770508\n",
      "Epoch/Iter:10/499, Dloss: 0.075395867228508, Gloss: 5.2177276611328125\n",
      "Epoch/Iter:10/599, Dloss: 0.046832628548145294, Gloss: 5.427803039550781\n",
      "Epoch/Iter:11/99, Dloss: 0.08039912581443787, Gloss: 5.505978584289551\n",
      "Epoch/Iter:11/199, Dloss: 0.01941767707467079, Gloss: 6.068878173828125\n",
      "Epoch/Iter:11/299, Dloss: 0.016411421820521355, Gloss: 6.258074760437012\n",
      "Epoch/Iter:11/399, Dloss: 0.31200161576271057, Gloss: 6.9933857917785645\n",
      "Epoch/Iter:11/499, Dloss: 0.03952767699956894, Gloss: 5.711988925933838\n",
      "Epoch/Iter:11/599, Dloss: 0.07866689562797546, Gloss: 6.1053619384765625\n",
      "Epoch/Iter:12/99, Dloss: 0.06751436740159988, Gloss: 5.797008514404297\n",
      "Epoch/Iter:12/199, Dloss: 3.261431932449341, Gloss: 6.6852498054504395\n",
      "Epoch/Iter:12/299, Dloss: 0.01956859603524208, Gloss: 5.767847061157227\n",
      "Epoch/Iter:12/399, Dloss: 0.05446932464838028, Gloss: 4.735129356384277\n",
      "Epoch/Iter:12/499, Dloss: 0.04196818917989731, Gloss: 5.14286470413208\n",
      "Epoch/Iter:12/599, Dloss: 0.33643513917922974, Gloss: 4.89560604095459\n",
      "Epoch/Iter:13/99, Dloss: 1.3223140239715576, Gloss: 6.637223243713379\n",
      "Epoch/Iter:13/199, Dloss: 0.03404266759753227, Gloss: 5.354341983795166\n",
      "Epoch/Iter:13/299, Dloss: 0.16868673264980316, Gloss: 4.844855308532715\n",
      "Epoch/Iter:13/399, Dloss: 0.22475571930408478, Gloss: 7.016689300537109\n",
      "Epoch/Iter:13/499, Dloss: 0.03163965791463852, Gloss: 6.302062034606934\n",
      "Epoch/Iter:13/599, Dloss: 0.013247832655906677, Gloss: 6.273165225982666\n",
      "Epoch/Iter:14/99, Dloss: 0.034046418964862823, Gloss: 5.913247108459473\n",
      "Epoch/Iter:14/199, Dloss: 0.08438120782375336, Gloss: 4.87943172454834\n",
      "Epoch/Iter:14/299, Dloss: 0.029078546911478043, Gloss: 4.886410713195801\n",
      "Epoch/Iter:14/399, Dloss: 0.1598430573940277, Gloss: 4.0586090087890625\n",
      "Epoch/Iter:14/499, Dloss: 0.07416658103466034, Gloss: 5.459827899932861\n",
      "Epoch/Iter:14/599, Dloss: 0.14951074123382568, Gloss: 4.656637191772461\n",
      "Epoch/Iter:15/99, Dloss: 0.04253893345594406, Gloss: 7.011533260345459\n",
      "Epoch/Iter:15/199, Dloss: 0.2696850895881653, Gloss: 4.945499420166016\n",
      "Epoch/Iter:15/299, Dloss: 0.11743190139532089, Gloss: 6.655374050140381\n",
      "Epoch/Iter:15/399, Dloss: 0.030608754605054855, Gloss: 6.39528751373291\n",
      "Epoch/Iter:15/499, Dloss: 0.29270222783088684, Gloss: 6.285706520080566\n",
      "Epoch/Iter:15/599, Dloss: 0.04462778568267822, Gloss: 4.828366756439209\n",
      "Epoch/Iter:16/99, Dloss: 0.08350802958011627, Gloss: 4.33610725402832\n",
      "Epoch/Iter:16/199, Dloss: 0.028526391834020615, Gloss: 5.557981491088867\n",
      "Epoch/Iter:16/299, Dloss: 0.0324583537876606, Gloss: 4.570960521697998\n",
      "Epoch/Iter:16/399, Dloss: 0.6841831207275391, Gloss: 7.165475845336914\n",
      "Epoch/Iter:16/499, Dloss: 0.05766264349222183, Gloss: 5.147984504699707\n",
      "Epoch/Iter:16/599, Dloss: 0.040580328553915024, Gloss: 5.484419345855713\n",
      "Epoch/Iter:17/99, Dloss: 2.3845741748809814, Gloss: 6.024657726287842\n",
      "Epoch/Iter:17/199, Dloss: 0.022504856809973717, Gloss: 5.698507785797119\n",
      "Epoch/Iter:17/299, Dloss: 1.2319343090057373, Gloss: 1.4483213424682617\n",
      "Epoch/Iter:17/399, Dloss: 0.5177579522132874, Gloss: 2.8104896545410156\n",
      "Epoch/Iter:17/499, Dloss: 0.10212087631225586, Gloss: 6.66806173324585\n",
      "Epoch/Iter:17/599, Dloss: 0.11916626989841461, Gloss: 4.880133152008057\n",
      "Epoch/Iter:18/99, Dloss: 0.5053980350494385, Gloss: 5.662660598754883\n",
      "Epoch/Iter:18/199, Dloss: 0.058115821331739426, Gloss: 5.084721565246582\n",
      "Epoch/Iter:18/299, Dloss: 0.09657127410173416, Gloss: 4.226816654205322\n",
      "Epoch/Iter:18/399, Dloss: 0.0725751668214798, Gloss: 5.4192304611206055\n",
      "Epoch/Iter:18/499, Dloss: 0.05611994117498398, Gloss: 4.848989486694336\n",
      "Epoch/Iter:18/599, Dloss: 0.07778754830360413, Gloss: 7.0547261238098145\n",
      "Epoch/Iter:19/99, Dloss: 0.03826550394296646, Gloss: 6.315323352813721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch/Iter:19/199, Dloss: 0.07615428417921066, Gloss: 5.925811767578125\n",
      "Epoch/Iter:19/299, Dloss: 0.03363516926765442, Gloss: 5.4948506355285645\n",
      "Epoch/Iter:19/399, Dloss: 0.12530186772346497, Gloss: 6.18087911605835\n",
      "Epoch/Iter:19/499, Dloss: 0.021310409530997276, Gloss: 6.340580940246582\n",
      "Epoch/Iter:19/599, Dloss: 0.07556824386119843, Gloss: 6.676409721374512\n",
      "Epoch/Iter:20/99, Dloss: 0.036128487437963486, Gloss: 5.577206134796143\n",
      "Epoch/Iter:20/199, Dloss: 0.030040476471185684, Gloss: 5.977469444274902\n",
      "Epoch/Iter:20/299, Dloss: 0.029988255351781845, Gloss: 5.273538589477539\n",
      "Epoch/Iter:20/399, Dloss: 0.02847667597234249, Gloss: 6.0708465576171875\n",
      "Epoch/Iter:20/499, Dloss: 0.007585631683468819, Gloss: 6.227371692657471\n",
      "Epoch/Iter:20/599, Dloss: 0.07143455743789673, Gloss: 6.247979640960693\n",
      "Epoch/Iter:21/99, Dloss: 0.08764276653528214, Gloss: 6.224170207977295\n",
      "Epoch/Iter:21/199, Dloss: 0.028515130281448364, Gloss: 6.63681697845459\n",
      "Epoch/Iter:21/299, Dloss: 0.1726539134979248, Gloss: 3.7799839973449707\n",
      "Epoch/Iter:21/399, Dloss: 0.056043192744255066, Gloss: 5.460265159606934\n",
      "Epoch/Iter:21/499, Dloss: 0.026914475485682487, Gloss: 5.153608798980713\n",
      "Epoch/Iter:21/599, Dloss: 0.22165900468826294, Gloss: 4.013969421386719\n",
      "Epoch/Iter:22/99, Dloss: 0.03946497663855553, Gloss: 4.717747211456299\n",
      "Epoch/Iter:22/199, Dloss: 0.0055078743025660515, Gloss: 7.58906888961792\n",
      "Epoch/Iter:22/299, Dloss: 0.08864761888980865, Gloss: 4.8124799728393555\n",
      "Epoch/Iter:22/399, Dloss: 0.0366535410284996, Gloss: 6.242258071899414\n",
      "Epoch/Iter:22/499, Dloss: 0.050232432782649994, Gloss: 6.302568435668945\n",
      "Epoch/Iter:22/599, Dloss: 0.02473619021475315, Gloss: 6.065555572509766\n",
      "Epoch/Iter:23/99, Dloss: 0.006616863422095776, Gloss: 6.89734411239624\n",
      "Epoch/Iter:23/199, Dloss: 0.03939337655901909, Gloss: 6.725512504577637\n",
      "Epoch/Iter:23/299, Dloss: 0.31654074788093567, Gloss: 2.3292946815490723\n",
      "Epoch/Iter:23/399, Dloss: 0.09099440276622772, Gloss: 7.744081020355225\n",
      "Epoch/Iter:23/499, Dloss: 0.15317924320697784, Gloss: 6.926012992858887\n",
      "Epoch/Iter:23/599, Dloss: 0.0722033753991127, Gloss: 5.9026618003845215\n",
      "Epoch/Iter:24/99, Dloss: 0.046275779604911804, Gloss: 6.124279022216797\n",
      "Epoch/Iter:24/199, Dloss: 0.09424436837434769, Gloss: 6.337564468383789\n",
      "Epoch/Iter:24/299, Dloss: 0.02309047058224678, Gloss: 5.86901330947876\n",
      "Epoch/Iter:24/399, Dloss: 0.013024439103901386, Gloss: 6.505824089050293\n",
      "Epoch/Iter:24/499, Dloss: 0.06307196617126465, Gloss: 5.145023822784424\n",
      "Epoch/Iter:24/599, Dloss: 0.047283802181482315, Gloss: 6.850282192230225\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for n, (images, _) in enumerate(train_loader):\n",
    "        bs = images.size(0)\n",
    "        images = images.cuda()\n",
    "        images = Variable(images)\n",
    "        #print(images.shape)\n",
    "        # Discriminator\n",
    "        optimizerD.zero_grad()\n",
    "        label = torch.Tensor(np.ones(bs))\n",
    "        label = label.cuda()\n",
    "        label = Variable(label,requires_grad=False)\n",
    "        feout1 =  FE(images)\n",
    "        real_prob = D(feout1)\n",
    "        real_loss = criterionD(real_prob,label)\n",
    "        real_loss.backward()\n",
    "        \n",
    "        z,idx = generate_noise(bs)\n",
    "        z = z.cuda()\n",
    "        z = Variable(z)\n",
    "        fake_img = G(z)\n",
    "        feout1 = FE(fake_img)\n",
    "        fake_prob = D(feout1)\n",
    "        label2 = torch.Tensor(np.zeros(bs))\n",
    "        label2 = label2.cuda()\n",
    "        label2 = Variable(label2,requires_grad = False)\n",
    "        fake_loss = criterionD(fake_prob,label2)\n",
    "        fake_loss.backward(retain_graph=True)\n",
    "        \n",
    "        D_loss = real_loss + fake_loss\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Generator and Q\n",
    "        optimizerG.zero_grad()\n",
    "        feout1 = FE(fake_img)\n",
    "        fake_prob = D(feout1)\n",
    "        label = torch.Tensor(np.ones(bs))\n",
    "        label = label.cuda()\n",
    "        label = Variable(label,requires_grad=False)\n",
    "        reconstruct_loss = criterionD(fake_prob,label)\n",
    "        \n",
    "        q_logits = QE(feout1)\n",
    "        class_ = torch.LongTensor(idx).cuda()\n",
    "        target = Variable(class_)\n",
    "        #print(q_logits.shape,target.shape)\n",
    "        q_loss = criterionQ(q_logits,target)\n",
    "        G_loss = reconstruct_loss + q_loss\n",
    "        G_loss.backward(retain_graph=True)\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if (n+1) % 100 == 0:\n",
    "            print('Epoch/Iter:{0}/{1}, Dloss: {2}, Gloss: {3}'.format(\n",
    "            epoch, n, D_loss.data.cpu().numpy(),\n",
    "            G_loss.data.cpu().numpy())\n",
    "          )  \n",
    "    test_images = G(fixed_z)\n",
    "    #print(test_images[0].shape)\n",
    "    save_image(test_images.data,'./samples/infoGAN2/epoch_{:d}_pytorch.png'.format(epoch),nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
