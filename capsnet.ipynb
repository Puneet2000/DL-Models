{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "traindata = datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "train_loader= torch.utils.data.DataLoader(traindata, batch_size=100,shuffle=True, num_workers=2)\n",
    "testdata = datasets.MNIST(root='./data', train=False,download=True, transform=transform)\n",
    "test_loader= torch.utils.data.DataLoader(testdata, batch_size=100,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self,in_channels=1,out_channels=256,kernel_size=9):\n",
    "        super(ConvLayer,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size,1)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self,num_capsules=8,in_channels=256,out_channels=32,kernel_size=9):\n",
    "        super(PrimaryCaps,self).__init__()\n",
    "        self.capsules = nn.ModuleList(nn.Conv2d(in_channels,out_channels,\n",
    "                                     kernel_size, 2,0) for _ in range(num_capsules))\n",
    "    def forward(self,x):\n",
    "        out = [capsule(x) for capsule in self.capsules]\n",
    "        out = torch.stack(out,dim=1) \n",
    "        out= out.view(out.size(0), 32 * 6 * 6, -1)\n",
    "        return self.squash(out)\n",
    "    \n",
    "    def squash(self,input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self,num_capsules=10,num_routes=32*6*6,in_channels=8,out_channels=16):\n",
    "        super(DigitCaps,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "        self.W = nn.Parameter(torch.randn(1,num_routes,num_capsules,out_channels,in_channels))\n",
    "    def forward(self,x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        u_hat = torch.matmul(W, x)\n",
    "        \n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "        b_ij = b_ij.cuda()\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = self.squash(s_j)\n",
    "            m= u_hat.transpose(3, 4)\n",
    "            #print(u_hat.shape,m.shape,v_j.shape)\n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "    \n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.reconstraction_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, data):\n",
    "        #print(x.shape)\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes)\n",
    "        #print(classes.shape)\n",
    "        \n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = Variable(torch.eye(10))\n",
    "        #print(masked.shape)\n",
    "        #print(max_length_indices)\n",
    "        masked = masked.cuda()\n",
    "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
    "        #print(masked.shape)\n",
    "        #print(masked[:, :, None, None].shape)\n",
    "        reconstructions = self.reconstraction_layers((x * masked[:, :, None, None]).view(x.size(0), -1))\n",
    "        reconstructions = reconstructions.view(-1, 1, 28, 28)\n",
    "        \n",
    "        return reconstructions, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv_layer = ConvLayer()\n",
    "        self.primary_capsules = PrimaryCaps()\n",
    "        self.digit_capsules = DigitCaps()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
    "        reconstructions, masked = self.decoder(output, data)\n",
    "        return output, reconstructions, masked\n",
    "    \n",
    "    def loss(self, data, x, target, reconstructions):\n",
    "        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
    "    \n",
    "    def margin_loss(self, x, labels, size_average=True):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
    "\n",
    "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def reconstruction_loss(self, data, reconstructions):\n",
    "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
    "        return loss * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_net = CapsNet()\n",
    "capsule_net = capsule_net.cuda()\n",
    "optimizer = optim.Adam(capsule_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy in epoch0: 0.15\n",
      "train accuracy in epoch0: 0.82\n",
      "train accuracy in epoch0: 0.76\n",
      "train accuracy in epoch0: 0.83\n",
      "train accuracy in epoch0: 0.89\n",
      "train accuracy in epoch0: 0.9\n",
      "tensor(0.4929, device='cuda:0')\n",
      "test accuracy in epoch0: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3059, device='cuda:0')\n",
      "train accuracy in epoch1: 0.88\n",
      "train accuracy in epoch1: 0.95\n",
      "train accuracy in epoch1: 0.9\n",
      "train accuracy in epoch1: 0.87\n",
      "train accuracy in epoch1: 0.89\n",
      "train accuracy in epoch1: 0.93\n",
      "tensor(0.2661, device='cuda:0')\n",
      "test accuracy in epoch1: 0.97\n",
      "tensor(0.2331, device='cuda:0')\n",
      "train accuracy in epoch2: 0.93\n",
      "train accuracy in epoch2: 0.89\n",
      "train accuracy in epoch2: 0.93\n",
      "train accuracy in epoch2: 0.94\n",
      "train accuracy in epoch2: 0.93\n",
      "train accuracy in epoch2: 0.95\n",
      "tensor(0.2195, device='cuda:0')\n",
      "test accuracy in epoch2: 0.98\n",
      "tensor(0.2094, device='cuda:0')\n",
      "train accuracy in epoch3: 0.96\n",
      "train accuracy in epoch3: 0.91\n",
      "train accuracy in epoch3: 0.93\n",
      "train accuracy in epoch3: 0.95\n",
      "train accuracy in epoch3: 0.96\n",
      "train accuracy in epoch3: 0.95\n",
      "tensor(0.1985, device='cuda:0')\n",
      "test accuracy in epoch3: 0.99\n",
      "tensor(0.1918, device='cuda:0')\n",
      "train accuracy in epoch4: 0.95\n",
      "train accuracy in epoch4: 0.94\n",
      "train accuracy in epoch4: 0.96\n",
      "train accuracy in epoch4: 0.93\n",
      "train accuracy in epoch4: 0.96\n",
      "train accuracy in epoch4: 0.94\n",
      "tensor(0.1859, device='cuda:0')\n",
      "test accuracy in epoch4: 1.0\n",
      "tensor(0.1827, device='cuda:0')\n",
      "train accuracy in epoch5: 0.97\n",
      "train accuracy in epoch5: 0.96\n",
      "train accuracy in epoch5: 0.95\n",
      "train accuracy in epoch5: 0.96\n",
      "train accuracy in epoch5: 0.95\n",
      "train accuracy in epoch5: 0.95\n",
      "tensor(0.1761, device='cuda:0')\n",
      "test accuracy in epoch5: 1.0\n",
      "tensor(0.1738, device='cuda:0')\n",
      "train accuracy in epoch6: 0.95\n",
      "train accuracy in epoch6: 0.95\n",
      "train accuracy in epoch6: 0.96\n",
      "train accuracy in epoch6: 0.99\n",
      "train accuracy in epoch6: 0.96\n",
      "train accuracy in epoch6: 0.94\n",
      "tensor(0.1699, device='cuda:0')\n",
      "test accuracy in epoch6: 1.0\n",
      "tensor(0.1702, device='cuda:0')\n",
      "train accuracy in epoch7: 0.95\n",
      "train accuracy in epoch7: 0.94\n",
      "train accuracy in epoch7: 0.93\n",
      "train accuracy in epoch7: 0.98\n",
      "train accuracy in epoch7: 0.97\n",
      "train accuracy in epoch7: 0.99\n",
      "tensor(0.1646, device='cuda:0')\n",
      "test accuracy in epoch7: 1.0\n",
      "tensor(0.1687, device='cuda:0')\n",
      "train accuracy in epoch8: 0.96\n",
      "train accuracy in epoch8: 0.97\n",
      "train accuracy in epoch8: 0.96\n",
      "train accuracy in epoch8: 0.98\n",
      "train accuracy in epoch8: 0.94\n",
      "train accuracy in epoch8: 0.95\n",
      "tensor(0.1599, device='cuda:0')\n",
      "test accuracy in epoch8: 1.0\n",
      "tensor(0.1578, device='cuda:0')\n",
      "train accuracy in epoch9: 0.99\n",
      "train accuracy in epoch9: 0.99\n",
      "train accuracy in epoch9: 0.95\n",
      "train accuracy in epoch9: 0.94\n",
      "train accuracy in epoch9: 0.95\n",
      "train accuracy in epoch9: 0.94\n",
      "tensor(0.1545, device='cuda:0')\n",
      "test accuracy in epoch9: 1.0\n",
      "tensor(0.1572, device='cuda:0')\n",
      "train accuracy in epoch10: 0.96\n",
      "train accuracy in epoch10: 0.93\n",
      "train accuracy in epoch10: 0.99\n",
      "train accuracy in epoch10: 0.89\n",
      "train accuracy in epoch10: 0.97\n",
      "train accuracy in epoch10: 0.94\n",
      "tensor(0.1525, device='cuda:0')\n",
      "test accuracy in epoch10: 1.0\n",
      "tensor(0.1538, device='cuda:0')\n",
      "train accuracy in epoch11: 0.96\n",
      "train accuracy in epoch11: 0.93\n",
      "train accuracy in epoch11: 0.91\n",
      "train accuracy in epoch11: 0.97\n",
      "train accuracy in epoch11: 0.97\n",
      "train accuracy in epoch11: 0.96\n",
      "tensor(0.1490, device='cuda:0')\n",
      "test accuracy in epoch11: 1.0\n",
      "tensor(0.1507, device='cuda:0')\n",
      "train accuracy in epoch12: 0.96\n",
      "train accuracy in epoch12: 0.96\n",
      "train accuracy in epoch12: 0.97\n",
      "train accuracy in epoch12: 0.99\n",
      "train accuracy in epoch12: 0.96\n",
      "train accuracy in epoch12: 0.95\n",
      "tensor(0.1455, device='cuda:0')\n",
      "test accuracy in epoch12: 1.0\n",
      "tensor(0.1496, device='cuda:0')\n",
      "train accuracy in epoch13: 0.96\n",
      "train accuracy in epoch13: 0.99\n",
      "train accuracy in epoch13: 0.93\n",
      "train accuracy in epoch13: 0.95\n",
      "train accuracy in epoch13: 0.96\n",
      "train accuracy in epoch13: 0.99\n",
      "tensor(0.1426, device='cuda:0')\n",
      "test accuracy in epoch13: 1.0\n",
      "tensor(0.1494, device='cuda:0')\n",
      "train accuracy in epoch14: 0.98\n",
      "train accuracy in epoch14: 0.95\n",
      "train accuracy in epoch14: 0.96\n",
      "train accuracy in epoch14: 0.97\n",
      "train accuracy in epoch14: 0.93\n",
      "train accuracy in epoch14: 0.96\n",
      "tensor(0.1413, device='cuda:0')\n",
      "test accuracy in epoch14: 1.0\n",
      "tensor(0.1429, device='cuda:0')\n",
      "train accuracy in epoch15: 0.97\n",
      "train accuracy in epoch15: 0.96\n",
      "train accuracy in epoch15: 0.97\n",
      "train accuracy in epoch15: 0.98\n",
      "train accuracy in epoch15: 0.98\n",
      "train accuracy in epoch15: 0.96\n",
      "tensor(0.1385, device='cuda:0')\n",
      "test accuracy in epoch15: 1.0\n",
      "tensor(0.1431, device='cuda:0')\n",
      "train accuracy in epoch16: 0.97\n",
      "train accuracy in epoch16: 0.98\n",
      "train accuracy in epoch16: 0.97\n",
      "train accuracy in epoch16: 0.94\n",
      "train accuracy in epoch16: 0.97\n",
      "train accuracy in epoch16: 0.98\n",
      "tensor(0.1366, device='cuda:0')\n",
      "test accuracy in epoch16: 1.0\n",
      "tensor(0.1434, device='cuda:0')\n",
      "train accuracy in epoch17: 0.99\n",
      "train accuracy in epoch17: 0.98\n",
      "train accuracy in epoch17: 0.99\n",
      "train accuracy in epoch17: 0.97\n",
      "train accuracy in epoch17: 0.95\n",
      "train accuracy in epoch17: 0.98\n",
      "tensor(0.1350, device='cuda:0')\n",
      "test accuracy in epoch17: 1.0\n",
      "tensor(0.1448, device='cuda:0')\n",
      "train accuracy in epoch18: 0.98\n",
      "train accuracy in epoch18: 0.95\n",
      "train accuracy in epoch18: 0.99\n",
      "train accuracy in epoch18: 0.98\n",
      "train accuracy in epoch18: 0.93\n",
      "train accuracy in epoch18: 0.95\n",
      "tensor(0.1325, device='cuda:0')\n",
      "test accuracy in epoch18: 1.0\n",
      "tensor(0.1409, device='cuda:0')\n",
      "train accuracy in epoch19: 0.98\n",
      "train accuracy in epoch19: 0.99\n",
      "train accuracy in epoch19: 0.95\n",
      "train accuracy in epoch19: 0.95\n",
      "train accuracy in epoch19: 0.96\n",
      "train accuracy in epoch19: 0.96\n",
      "tensor(0.1314, device='cuda:0')\n",
      "test accuracy in epoch19: 1.0\n",
      "tensor(0.1405, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 20\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    capsule_net.train()\n",
    "    train_loss = 0\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        target = torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        \n",
    "        if batch_id % 100 == 0:\n",
    "            print (\"train accuracy in epoch{0}:\".format(epoch), sum(np.argmax(masked.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(target.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "        \n",
    "    print( train_loss / len(train_loader))\n",
    "        \n",
    "    capsule_net.eval()\n",
    "    test_loss = 0\n",
    "    for batch_id, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        target = torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "        \n",
    "        if batch_id % 100 == 0:\n",
    "            print (\"test accuracy in epoch{0}:\".format(epoch), sum(np.argmax(masked.data.cpu().numpy(), 1) == \n",
    "                                   np.argmax(target.data.cpu().numpy(), 1)) / float(batch_size))\n",
    "            save_image(reconstructions.data,\"./samples/CAPSNET/output.png\",nrow=10)\n",
    "    \n",
    "    print (test_loss / len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
