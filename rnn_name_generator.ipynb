{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFiles(path): return glob.glob(path)\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('./names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "def targetTensor(line):\n",
    "    #print(line)\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    #print(torch.LongTensor(letter_indexes))\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =[(categoryTensor(category),lineToTensor(line),targetTensor(line)) for category in category_lines for line in category_lines[category]]\n",
    "shuffle(dataset)\n",
    "dataset = dataset[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "#rnn = rnn.cuda()\n",
    "criterion = nn.NLLLoss()\n",
    "optimzer = optim.SGD(rnn.parameters(),lr=0.0001)\n",
    "n_epochs =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at epoch 0 is  26.568\n",
      "training loss at epoch 1 is  22.6048\n",
      "training loss at epoch 2 is  21.6686\n",
      "training loss at epoch 3 is  21.112\n",
      "training loss at epoch 4 is  20.7696\n",
      "training loss at epoch 5 is  20.4924\n",
      "training loss at epoch 6 is  20.234\n",
      "training loss at epoch 7 is  20.0386\n",
      "training loss at epoch 8 is  19.795\n",
      "training loss at epoch 9 is  19.5884\n",
      "training loss at epoch 10 is  19.4412\n",
      "training loss at epoch 11 is  19.2522\n",
      "training loss at epoch 12 is  19.0974\n",
      "training loss at epoch 13 is  18.9924\n",
      "training loss at epoch 14 is  18.8588\n",
      "training loss at epoch 15 is  18.759\n",
      "training loss at epoch 16 is  18.617\n",
      "training loss at epoch 17 is  18.5882\n",
      "training loss at epoch 18 is  18.4322\n",
      "training loss at epoch 19 is  18.3686\n",
      "training loss at epoch 20 is  18.255\n",
      "training loss at epoch 21 is  18.1948\n",
      "training loss at epoch 22 is  18.1072\n",
      "training loss at epoch 23 is  17.9888\n",
      "training loss at epoch 24 is  17.947\n",
      "training loss at epoch 25 is  17.88\n",
      "training loss at epoch 26 is  17.8252\n",
      "training loss at epoch 27 is  17.7782\n",
      "training loss at epoch 28 is  17.7276\n",
      "training loss at epoch 29 is  17.6918\n",
      "training loss at epoch 30 is  17.6368\n",
      "training loss at epoch 31 is  17.5588\n",
      "training loss at epoch 32 is  17.5256\n",
      "training loss at epoch 33 is  17.4662\n",
      "training loss at epoch 34 is  17.4358\n",
      "training loss at epoch 35 is  17.422\n",
      "training loss at epoch 36 is  17.355\n",
      "training loss at epoch 37 is  17.3134\n",
      "training loss at epoch 38 is  17.3048\n",
      "training loss at epoch 39 is  17.2448\n",
      "training loss at epoch 40 is  17.2186\n",
      "training loss at epoch 41 is  17.1864\n",
      "training loss at epoch 42 is  17.1344\n",
      "training loss at epoch 43 is  17.1742\n",
      "training loss at epoch 44 is  17.1214\n",
      "training loss at epoch 45 is  17.0684\n",
      "training loss at epoch 46 is  17.0722\n",
      "training loss at epoch 47 is  17.0296\n",
      "training loss at epoch 48 is  17.008\n",
      "training loss at epoch 49 is  16.9808\n",
      "training loss at epoch 50 is  16.9504\n",
      "training loss at epoch 51 is  16.9566\n",
      "training loss at epoch 52 is  16.9316\n",
      "training loss at epoch 53 is  16.9106\n",
      "training loss at epoch 54 is  16.8582\n",
      "training loss at epoch 55 is  16.9\n",
      "training loss at epoch 56 is  16.807\n",
      "training loss at epoch 57 is  16.8386\n",
      "training loss at epoch 58 is  16.8164\n",
      "training loss at epoch 59 is  16.7298\n",
      "training loss at epoch 60 is  16.7616\n",
      "training loss at epoch 61 is  16.737\n",
      "training loss at epoch 62 is  16.7018\n",
      "training loss at epoch 63 is  16.7246\n",
      "training loss at epoch 64 is  16.681\n",
      "training loss at epoch 65 is  16.6438\n",
      "training loss at epoch 66 is  16.6502\n",
      "training loss at epoch 67 is  16.6434\n",
      "training loss at epoch 68 is  16.654\n",
      "training loss at epoch 69 is  16.621\n",
      "training loss at epoch 70 is  16.5866\n",
      "training loss at epoch 71 is  16.5492\n",
      "training loss at epoch 72 is  16.5862\n",
      "training loss at epoch 73 is  16.4986\n",
      "training loss at epoch 74 is  16.524\n",
      "training loss at epoch 75 is  16.5426\n",
      "training loss at epoch 76 is  16.5522\n",
      "training loss at epoch 77 is  16.4792\n",
      "training loss at epoch 78 is  16.4596\n",
      "training loss at epoch 79 is  16.4594\n",
      "training loss at epoch 80 is  16.4052\n",
      "training loss at epoch 81 is  16.4148\n",
      "training loss at epoch 82 is  16.4536\n",
      "training loss at epoch 83 is  16.428\n",
      "training loss at epoch 84 is  16.404\n",
      "training loss at epoch 85 is  16.3776\n",
      "training loss at epoch 86 is  16.3902\n",
      "training loss at epoch 87 is  16.3342\n",
      "training loss at epoch 88 is  16.3288\n",
      "training loss at epoch 89 is  16.2962\n",
      "training loss at epoch 90 is  16.3244\n",
      "training loss at epoch 91 is  16.2806\n",
      "training loss at epoch 92 is  16.2464\n",
      "training loss at epoch 93 is  16.2766\n",
      "training loss at epoch 94 is  16.282\n",
      "training loss at epoch 95 is  16.2826\n",
      "training loss at epoch 96 is  16.2352\n",
      "training loss at epoch 97 is  16.2424\n",
      "training loss at epoch 98 is  16.2726\n",
      "training loss at epoch 99 is  16.232\n",
      "training loss at epoch 100 is  16.213\n",
      "training loss at epoch 101 is  16.2222\n",
      "training loss at epoch 102 is  16.1722\n",
      "training loss at epoch 103 is  16.1658\n",
      "training loss at epoch 104 is  16.189\n",
      "training loss at epoch 105 is  16.137\n",
      "training loss at epoch 106 is  16.1\n",
      "training loss at epoch 107 is  16.1004\n",
      "training loss at epoch 108 is  16.0828\n",
      "training loss at epoch 109 is  16.124\n",
      "training loss at epoch 110 is  16.1286\n",
      "training loss at epoch 111 is  16.0792\n",
      "training loss at epoch 112 is  16.112\n",
      "training loss at epoch 113 is  16.0656\n",
      "training loss at epoch 114 is  16.0518\n",
      "training loss at epoch 115 is  16.0536\n",
      "training loss at epoch 116 is  16.08\n",
      "training loss at epoch 117 is  16.0716\n",
      "training loss at epoch 118 is  16.0398\n",
      "training loss at epoch 119 is  16.0504\n",
      "training loss at epoch 120 is  16.0242\n",
      "training loss at epoch 121 is  16.0146\n",
      "training loss at epoch 122 is  15.9928\n",
      "training loss at epoch 123 is  16.0352\n",
      "training loss at epoch 124 is  15.9558\n",
      "training loss at epoch 125 is  15.9958\n",
      "training loss at epoch 126 is  15.9568\n",
      "training loss at epoch 127 is  15.9304\n",
      "training loss at epoch 128 is  15.9444\n",
      "training loss at epoch 129 is  15.9288\n",
      "training loss at epoch 130 is  15.9448\n",
      "training loss at epoch 131 is  15.9284\n",
      "training loss at epoch 132 is  15.9576\n",
      "training loss at epoch 133 is  15.8976\n",
      "training loss at epoch 134 is  15.8234\n",
      "training loss at epoch 135 is  15.8676\n",
      "training loss at epoch 136 is  15.8594\n",
      "training loss at epoch 137 is  15.8628\n",
      "training loss at epoch 138 is  15.8832\n",
      "training loss at epoch 139 is  15.8692\n",
      "training loss at epoch 140 is  15.856\n",
      "training loss at epoch 141 is  15.8232\n",
      "training loss at epoch 142 is  15.8246\n",
      "training loss at epoch 143 is  15.8444\n",
      "training loss at epoch 144 is  15.8222\n",
      "training loss at epoch 145 is  15.8182\n",
      "training loss at epoch 146 is  15.8264\n",
      "training loss at epoch 147 is  15.8114\n",
      "training loss at epoch 148 is  15.7992\n",
      "training loss at epoch 149 is  15.8438\n",
      "training loss at epoch 150 is  15.827\n",
      "training loss at epoch 151 is  15.7704\n",
      "training loss at epoch 152 is  15.7642\n",
      "training loss at epoch 153 is  15.7936\n",
      "training loss at epoch 154 is  15.7472\n",
      "training loss at epoch 155 is  15.7422\n",
      "training loss at epoch 156 is  15.7668\n",
      "training loss at epoch 157 is  15.749\n",
      "training loss at epoch 158 is  15.7488\n",
      "training loss at epoch 159 is  15.7068\n",
      "training loss at epoch 160 is  15.7548\n",
      "training loss at epoch 161 is  15.7474\n",
      "training loss at epoch 162 is  15.728\n",
      "training loss at epoch 163 is  15.7038\n",
      "training loss at epoch 164 is  15.6694\n",
      "training loss at epoch 165 is  15.6816\n",
      "training loss at epoch 166 is  15.7108\n",
      "training loss at epoch 167 is  15.6888\n",
      "training loss at epoch 168 is  15.7162\n",
      "training loss at epoch 169 is  15.644\n",
      "training loss at epoch 170 is  15.6698\n",
      "training loss at epoch 171 is  15.608\n",
      "training loss at epoch 172 is  15.6488\n",
      "training loss at epoch 173 is  15.6552\n",
      "training loss at epoch 174 is  15.651\n",
      "training loss at epoch 175 is  15.625\n",
      "training loss at epoch 176 is  15.6488\n",
      "training loss at epoch 177 is  15.6574\n",
      "training loss at epoch 178 is  15.6422\n",
      "training loss at epoch 179 is  15.5962\n",
      "training loss at epoch 180 is  15.6362\n",
      "training loss at epoch 181 is  15.6138\n",
      "training loss at epoch 182 is  15.5716\n",
      "training loss at epoch 183 is  15.559\n",
      "training loss at epoch 184 is  15.5804\n",
      "training loss at epoch 185 is  15.545\n",
      "training loss at epoch 186 is  15.563\n",
      "training loss at epoch 187 is  15.5622\n",
      "training loss at epoch 188 is  15.5858\n",
      "training loss at epoch 189 is  15.625\n",
      "training loss at epoch 190 is  15.6126\n",
      "training loss at epoch 191 is  15.5646\n",
      "training loss at epoch 192 is  15.5662\n",
      "training loss at epoch 193 is  15.5296\n",
      "training loss at epoch 194 is  15.581\n",
      "training loss at epoch 195 is  15.5846\n",
      "training loss at epoch 196 is  15.5756\n",
      "training loss at epoch 197 is  15.5348\n",
      "training loss at epoch 198 is  15.5324\n",
      "training loss at epoch 199 is  15.531\n",
      "training loss at epoch 200 is  15.52\n",
      "training loss at epoch 201 is  15.5368\n",
      "training loss at epoch 202 is  15.523\n",
      "training loss at epoch 203 is  15.532\n",
      "training loss at epoch 204 is  15.5552\n",
      "training loss at epoch 205 is  15.489\n",
      "training loss at epoch 206 is  15.5408\n",
      "training loss at epoch 207 is  15.4496\n",
      "training loss at epoch 208 is  15.504\n",
      "training loss at epoch 209 is  15.4608\n",
      "training loss at epoch 210 is  15.498\n",
      "training loss at epoch 211 is  15.4602\n",
      "training loss at epoch 212 is  15.465\n",
      "training loss at epoch 213 is  15.4766\n",
      "training loss at epoch 214 is  15.4388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at epoch 215 is  15.4196\n",
      "training loss at epoch 216 is  15.5158\n",
      "training loss at epoch 217 is  15.4448\n",
      "training loss at epoch 218 is  15.4892\n",
      "training loss at epoch 219 is  15.4104\n",
      "training loss at epoch 220 is  15.399\n",
      "training loss at epoch 221 is  15.4528\n",
      "training loss at epoch 222 is  15.4086\n",
      "training loss at epoch 223 is  15.4186\n",
      "training loss at epoch 224 is  15.4374\n",
      "training loss at epoch 225 is  15.397\n",
      "training loss at epoch 226 is  15.374\n",
      "training loss at epoch 227 is  15.3776\n",
      "training loss at epoch 228 is  15.4108\n",
      "training loss at epoch 229 is  15.4126\n",
      "training loss at epoch 230 is  15.4122\n",
      "training loss at epoch 231 is  15.4076\n",
      "training loss at epoch 232 is  15.377\n",
      "training loss at epoch 233 is  15.41\n",
      "training loss at epoch 234 is  15.4258\n",
      "training loss at epoch 235 is  15.3978\n",
      "training loss at epoch 236 is  15.3516\n",
      "training loss at epoch 237 is  15.4526\n",
      "training loss at epoch 238 is  15.405\n",
      "training loss at epoch 239 is  15.3534\n",
      "training loss at epoch 240 is  15.3562\n",
      "training loss at epoch 241 is  15.3538\n",
      "training loss at epoch 242 is  15.3714\n",
      "training loss at epoch 243 is  15.3938\n",
      "training loss at epoch 244 is  15.3726\n",
      "training loss at epoch 245 is  15.311\n"
     ]
    }
   ],
   "source": [
    "epoch_loss =0\n",
    "all_losses=[]\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss=0\n",
    "    for (category_tensor,line_tensor,target_tensor) in dataset:\n",
    "        hidden = rnn.initHidden()\n",
    "        optimzer.zero_grad()\n",
    "        loss =0\n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(category_tensor,line_tensor[i], hidden)\n",
    "            l= criterion(output, torch.tensor([int(target_tensor[i])], dtype=torch.long))\n",
    "            loss+=l\n",
    "        epoch_loss+=loss\n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "    print(\"training loss at epoch {0} is \".format(epoch),int(epoch_loss)/len(dataset))\n",
    "    all_losses.append(int(epoch_loss)/len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.savefig(\"./samples/rnn_name_generator.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
