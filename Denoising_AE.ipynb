{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiseAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoiseAutoEncoder,self).__init__()\n",
    "        self.drop = nn.Dropout(0.4)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Linear(1000,500),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(500,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Linear(1000,28*28),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784)\n",
    "        #print(x.shape)\n",
    "        noisex = self.drop(x)\n",
    "        en =  self.encoder(noisex)\n",
    "        de = self.decoder(en)\n",
    "        de = de.view(-1,1,28,28)\n",
    "        return x.view(-1,1,28,28),noisex.view(-1,1,28,28),de\n",
    "\n",
    "dAE = DenoiseAutoEncoder()\n",
    "dAE = dAE.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion=nn.MSELoss()\n",
    "optimizer = torch.optim.SGD( dAE.parameters(), lr=0.01)\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "realimages = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "train_loader= torch.utils.data.DataLoader(realimages, batch_size=50,shuffle=True, num_workers=2)\n",
    "it = iter(train_loader)\n",
    "fdata,_ = it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/30], loss:1.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infero/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [2/30], loss:0.9917\n",
      "epoch [3/30], loss:0.9464\n",
      "epoch [4/30], loss:0.9156\n",
      "epoch [5/30], loss:0.9153\n",
      "epoch [6/30], loss:0.9127\n",
      "epoch [7/30], loss:0.9166\n",
      "epoch [8/30], loss:0.9200\n",
      "epoch [9/30], loss:0.9048\n",
      "epoch [10/30], loss:0.9028\n",
      "epoch [11/30], loss:0.8990\n",
      "epoch [12/30], loss:0.8999\n",
      "epoch [13/30], loss:0.8961\n",
      "epoch [14/30], loss:0.8935\n",
      "epoch [15/30], loss:0.9061\n",
      "epoch [16/30], loss:0.8938\n",
      "epoch [17/30], loss:0.8897\n",
      "epoch [18/30], loss:0.8987\n",
      "epoch [19/30], loss:0.8998\n",
      "epoch [20/30], loss:0.9007\n",
      "epoch [21/30], loss:0.9014\n",
      "epoch [22/30], loss:0.9033\n",
      "epoch [23/30], loss:0.8925\n",
      "epoch [24/30], loss:0.8968\n",
      "epoch [25/30], loss:0.8948\n",
      "epoch [26/30], loss:0.8938\n",
      "epoch [27/30], loss:0.8856\n",
      "epoch [28/30], loss:0.8851\n",
      "epoch [29/30], loss:0.8881\n",
      "epoch [30/30], loss:0.8843\n",
      "epoch [31/30], loss:0.8837\n",
      "epoch [32/30], loss:0.8899\n",
      "epoch [33/30], loss:0.8882\n",
      "epoch [34/30], loss:0.8740\n",
      "epoch [35/30], loss:0.8819\n",
      "epoch [36/30], loss:0.8860\n",
      "epoch [37/30], loss:0.8909\n",
      "epoch [38/30], loss:0.8836\n",
      "epoch [39/30], loss:0.8888\n",
      "epoch [40/30], loss:0.8727\n",
      "epoch [41/30], loss:0.8751\n",
      "epoch [42/30], loss:0.8775\n",
      "epoch [43/30], loss:0.8815\n",
      "epoch [44/30], loss:0.8737\n",
      "epoch [45/30], loss:0.8751\n",
      "epoch [46/30], loss:0.8705\n",
      "epoch [47/30], loss:0.8764\n",
      "epoch [48/30], loss:0.8733\n",
      "epoch [49/30], loss:0.8718\n",
      "epoch [50/30], loss:0.8707\n",
      "epoch [51/30], loss:0.8721\n",
      "epoch [52/30], loss:0.8760\n",
      "epoch [53/30], loss:0.8704\n",
      "epoch [54/30], loss:0.8792\n",
      "epoch [55/30], loss:0.8846\n",
      "epoch [56/30], loss:0.8680\n",
      "epoch [57/30], loss:0.8779\n",
      "epoch [58/30], loss:0.8692\n",
      "epoch [59/30], loss:0.8787\n",
      "epoch [60/30], loss:0.8708\n",
      "epoch [61/30], loss:0.8607\n",
      "epoch [62/30], loss:0.8720\n",
      "epoch [63/30], loss:0.8639\n",
      "epoch [64/30], loss:0.8789\n",
      "epoch [65/30], loss:0.8772\n",
      "epoch [66/30], loss:0.8697\n",
      "epoch [67/30], loss:0.8763\n",
      "epoch [68/30], loss:0.8752\n",
      "epoch [69/30], loss:0.8642\n",
      "epoch [70/30], loss:0.8714\n",
      "epoch [71/30], loss:0.8761\n",
      "epoch [72/30], loss:0.8617\n",
      "epoch [73/30], loss:0.8726\n",
      "epoch [74/30], loss:0.8694\n",
      "epoch [75/30], loss:0.8650\n",
      "epoch [76/30], loss:0.8733\n",
      "epoch [77/30], loss:0.8712\n",
      "epoch [78/30], loss:0.8657\n",
      "epoch [79/30], loss:0.8702\n",
      "epoch [80/30], loss:0.8685\n",
      "epoch [81/30], loss:0.8683\n",
      "epoch [82/30], loss:0.8784\n",
      "epoch [83/30], loss:0.8680\n",
      "epoch [84/30], loss:0.8662\n",
      "epoch [85/30], loss:0.8756\n",
      "epoch [86/30], loss:0.8707\n",
      "epoch [87/30], loss:0.8584\n",
      "epoch [88/30], loss:0.8554\n",
      "epoch [89/30], loss:0.8653\n",
      "epoch [90/30], loss:0.8615\n",
      "epoch [91/30], loss:0.8688\n",
      "epoch [92/30], loss:0.8814\n",
      "epoch [93/30], loss:0.8712\n",
      "epoch [94/30], loss:0.8662\n",
      "epoch [95/30], loss:0.8630\n",
      "epoch [96/30], loss:0.8700\n",
      "epoch [97/30], loss:0.8812\n",
      "epoch [98/30], loss:0.8591\n",
      "epoch [99/30], loss:0.8647\n",
      "epoch [100/30], loss:0.8641\n",
      "epoch [101/30], loss:0.8656\n",
      "epoch [102/30], loss:0.8682\n",
      "epoch [103/30], loss:0.8585\n",
      "epoch [104/30], loss:0.8651\n",
      "epoch [105/30], loss:0.8643\n",
      "epoch [106/30], loss:0.8622\n",
      "epoch [107/30], loss:0.8749\n",
      "epoch [108/30], loss:0.8584\n",
      "epoch [109/30], loss:0.8703\n",
      "epoch [110/30], loss:0.8751\n",
      "epoch [111/30], loss:0.8597\n",
      "epoch [112/30], loss:0.8548\n",
      "epoch [113/30], loss:0.8670\n",
      "epoch [114/30], loss:0.8611\n",
      "epoch [115/30], loss:0.8638\n",
      "epoch [116/30], loss:0.8755\n",
      "epoch [117/30], loss:0.8560\n",
      "epoch [118/30], loss:0.8569\n",
      "epoch [119/30], loss:0.8640\n",
      "epoch [120/30], loss:0.8621\n",
      "epoch [121/30], loss:0.8625\n",
      "epoch [122/30], loss:0.8564\n",
      "epoch [123/30], loss:0.8725\n",
      "epoch [124/30], loss:0.8592\n",
      "epoch [125/30], loss:0.8644\n",
      "epoch [126/30], loss:0.8654\n",
      "epoch [127/30], loss:0.8617\n",
      "epoch [128/30], loss:0.8666\n",
      "epoch [129/30], loss:0.8691\n",
      "epoch [130/30], loss:0.8620\n",
      "epoch [131/30], loss:0.8516\n",
      "epoch [132/30], loss:0.8578\n",
      "epoch [133/30], loss:0.8485\n",
      "epoch [134/30], loss:0.8670\n",
      "epoch [135/30], loss:0.8651\n",
      "epoch [136/30], loss:0.8547\n",
      "epoch [137/30], loss:0.8584\n",
      "epoch [138/30], loss:0.8655\n",
      "epoch [139/30], loss:0.8678\n",
      "epoch [140/30], loss:0.8686\n",
      "epoch [141/30], loss:0.8568\n",
      "epoch [142/30], loss:0.8648\n",
      "epoch [143/30], loss:0.8674\n",
      "epoch [144/30], loss:0.8721\n",
      "epoch [145/30], loss:0.8451\n",
      "epoch [146/30], loss:0.8744\n",
      "epoch [147/30], loss:0.8669\n",
      "epoch [148/30], loss:0.8718\n",
      "epoch [149/30], loss:0.8660\n",
      "epoch [150/30], loss:0.8576\n",
      "epoch [151/30], loss:0.8568\n",
      "epoch [152/30], loss:0.8546\n",
      "epoch [153/30], loss:0.8674\n",
      "epoch [154/30], loss:0.8630\n",
      "epoch [155/30], loss:0.8575\n",
      "epoch [156/30], loss:0.8638\n",
      "epoch [157/30], loss:0.8510\n",
      "epoch [158/30], loss:0.8608\n",
      "epoch [159/30], loss:0.8588\n",
      "epoch [160/30], loss:0.8627\n",
      "epoch [161/30], loss:0.8562\n",
      "epoch [162/30], loss:0.8490\n",
      "epoch [163/30], loss:0.8492\n",
      "epoch [164/30], loss:0.8657\n",
      "epoch [165/30], loss:0.8648\n",
      "epoch [166/30], loss:0.8719\n",
      "epoch [167/30], loss:0.8544\n",
      "epoch [168/30], loss:0.8441\n",
      "epoch [169/30], loss:0.8707\n",
      "epoch [170/30], loss:0.8647\n",
      "epoch [171/30], loss:0.8631\n",
      "epoch [172/30], loss:0.8577\n",
      "epoch [173/30], loss:0.8535\n",
      "epoch [174/30], loss:0.8593\n",
      "epoch [175/30], loss:0.8673\n",
      "epoch [176/30], loss:0.8635\n",
      "epoch [177/30], loss:0.8520\n",
      "epoch [178/30], loss:0.8672\n",
      "epoch [179/30], loss:0.8524\n",
      "epoch [180/30], loss:0.8590\n",
      "epoch [181/30], loss:0.8514\n",
      "epoch [182/30], loss:0.8744\n",
      "epoch [183/30], loss:0.8582\n",
      "epoch [184/30], loss:0.8626\n",
      "epoch [185/30], loss:0.8486\n",
      "epoch [186/30], loss:0.8635\n",
      "epoch [187/30], loss:0.8479\n",
      "epoch [188/30], loss:0.8584\n",
      "epoch [189/30], loss:0.8569\n",
      "epoch [190/30], loss:0.8620\n",
      "epoch [191/30], loss:0.8552\n",
      "epoch [192/30], loss:0.8513\n",
      "epoch [193/30], loss:0.8667\n",
      "epoch [194/30], loss:0.8630\n",
      "epoch [195/30], loss:0.8600\n",
      "epoch [196/30], loss:0.8525\n",
      "epoch [197/30], loss:0.8588\n",
      "epoch [198/30], loss:0.8426\n",
      "epoch [199/30], loss:0.8568\n",
      "epoch [200/30], loss:0.8607\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for data,_ in train_loader:    \n",
    "        optimizer.zero_grad()\n",
    "        data=Variable(data.cuda())\n",
    "        actual,corrupted,output=dAE(data)\n",
    "        loss=loss_criterion(output,data)\n",
    "        loss.backward()     \n",
    "        optimizer.step()\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, 30, loss.data[0]))\n",
    "    actual,corrupted,output = dAE(fdata.cuda())\n",
    "    if epoch % 10 == 0:\n",
    "        save_image(actual.data, './GANs/samples/DAE/actual2.png'.format(epoch),nrow=10)\n",
    "        save_image(corrupted.data, './GANs/samples/DAE/corrupted2.png'.format(epoch),nrow=10)\n",
    "        save_image(output.data, './GANs/samples/DAE/output2.png'.format(epoch),nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
